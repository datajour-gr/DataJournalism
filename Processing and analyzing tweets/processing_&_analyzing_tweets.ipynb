{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "processing_&_analyzing_tweets.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNJl9U+mF6j7tuuqTCc8YRG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tsparaskevas/DataJournalism/blob/main/Processing%20and%20analyzing%20tweets/processing_%26_analyzing_tweets.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Processing & Analyzing tweets**"
      ],
      "metadata": {
        "id": "7JKb5gs7qrk9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ΣΗΜΕΙΩΣΗ:** Αυτό τo notebook στοχεύει στην επεξήγηση της διαδικασίας και στην επανάληψη. Εσείς στην εργασία σας θα χρησιμοποιήσετε από εδώ ό,τι θέλετε και αν θέλετε.\n",
        "\n",
        "Καλή επιτυχία!!!"
      ],
      "metadata": {
        "id": "cERNF7QpLTDD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Εγκατάσταση της Spacy (για επεξεργασία κειμένων στα ελληνικά)**"
      ],
      "metadata": {
        "id": "XGgWLp_DrJVD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Αρχικά κάνουμε εγκατάσταση (σβήνουμε το ```#``` και τρέχουμε το cell)\n",
        "2. Μόλις εγκατασταθεί ξαναβάζουμε το ```#```\n",
        "3. Κάνουμε Runtime > Restart runtime\n",
        "\n"
      ],
      "metadata": {
        "id": "mwV7ri9JQFN7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kGm1RCudqoNb"
      },
      "outputs": [],
      "source": [
        "#!python -m spacy download el_core_news_sm"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Εισαγωγή βιβλιοθηκών**"
      ],
      "metadata": {
        "id": "EwoBjSver2_J"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h7v0RpAKchL_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ca861309-8e70-431b-f380-0220c95d1e36"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np \n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('gdrive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Εισαγωγή και προετοιμασία των δεδομένων (tweets sets)**"
      ],
      "metadata": {
        "id": "3XQGXx4Qsm1i"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Αλλάζουμε τις ρυθμίσεις στο display των pandas για να μπορούμε να δούμε περισσότερα μέσα στα cells"
      ],
      "metadata": {
        "id": "PXvWoVajs2GS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Μεγιστοποίηση του πλάτους της στήλης για εμφάνιση ολόκληρου του κειμένου\n",
        "pd.set_option('display.max_colwidth', None)"
      ],
      "metadata": {
        "id": "toHl5mhmsz1i"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####**Πρώτο dataset** (δώστε το όνομα του δικού σας πρώτου dataset)"
      ],
      "metadata": {
        "id": "NoxwLrcZtiQr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Στον παρακάτω κώδικα δώστε το όνομα που θέλετε να έχει το full_tweets_df και κάντε τις απαραίτητες αλλαγές όπου χρειάζεται."
      ],
      "metadata": {
        "id": "aD61VpKH0srf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import & View data\n",
        "\n",
        "# hint: όπως μας έδειξε ο Χάρης, μπορούμε να βρούμε και να κάνουμε copy paste το path του επιθυμητού tsv από το εικονίδιο του φακέλου στο κάθετο μενού αριστερά\n",
        "onoma_a_full_tweets_df = pd.read_csv(\"το/πλήρες/path/του/tsv/arxeiou\", sep='\\t') \n",
        "# View data\n",
        "print(onoma_a_full_tweets_df.shape)\n",
        "print(f\"dtype of 'created_at' is: {onoma_a_full_tweets_df.created_at.dtypes}. To θέλουμε σε datetime64[ns]\") #\n",
        "onoma_a_full_tweets_df.head(1)"
      ],
      "metadata": {
        "id": "r-XI5tv7t2tU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert date to datetime to a new column (με την εντολή to_datetime) \n",
        "onoma_a_full_tweets_df['datetime'] = pd.to_datetime(onoma_a_full_tweets_df['created_at'], format='%a %b %d %H:%M:%S +0000 %Y')"
      ],
      "metadata": {
        "id": "IUblfvqewDXJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make a dataframe with selected columns only\n",
        "onoma_a_tweets_df = onoma_a_full_tweets_df[['datetime', \"full_text\"]]\n",
        "\n",
        "# Extract year, month and day from daytime\n",
        "onoma_a_tweets_df['year'] = pd.DatetimeIndex(onoma_a_tweets_df['datetime']).year\n",
        "onoma_a_tweets_df['month'] = pd.DatetimeIndex(onoma_a_tweets_df['datetime']).month\n",
        "onoma_a_tweets_df['day'] = pd.DatetimeIndex(onoma_a_tweets_df['datetime']).day\n",
        "\n",
        "# View dataframe info\n",
        "print(onoma_a_tweets_df.info())\n",
        "onoma_a_tweets_df.head(1)"
      ],
      "metadata": {
        "id": "n4Me9maaw2M4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Φτιάξτε ένα γράφημα για το πλήθος των tweets ανά έτος"
      ],
      "metadata": {
        "id": "bBkIHKAm4r1Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Make a barplot of tweets per year\n",
        "onoma_a_tweets_df['year'].value_counts().plot(kind='bar')"
      ],
      "metadata": {
        "id": "dKwp15KM21nO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Καθάρισμα του κειμένου**"
      ],
      "metadata": {
        "id": "T0jNt9Xt6bIh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove any urls in tweets' full_text (replace with space)\n",
        "onoma_a_tweets_df['clean_text'] = onoma_a_tweets_df['full_text'].str.replace(r'https?:\\/\\/.*[\\r\\n]*',\" \")"
      ],
      "metadata": {
        "id": "02eb5OON12R1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Μπορείτε να κάνετε και περισσότερο καθάρισμα στο κείμενο από σκουπίδια, με τη χρήση regex (regular expressions = κανονικές εκφράσεις) που θα μάθουμε σε επόμενο μάθημα."
      ],
      "metadata": {
        "id": "MlkbO2HD3eiO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Replace unwanted characters with spaces or nothing\n",
        "onoma_a_tweets_df['clean_text'] = onoma_a_tweets_df['clean_text'].str.replace(r'[\\n]*\\s*https?:\\/\\/.*[\\r\\n]*',\" \").str.replace(r'\\n*',\"\").str.replace(r'[▪️🟢⚪👉]*',\"\").str.replace(r\"\\w\\/\\w\", \"\")\n",
        "onoma_a_tweets_df['clean_text'] = onoma_a_tweets_df['clean_text'].str.replace('amp;', '').str.replace(r'[\\!\\-\\:\\,\\.«»\\\"“”\\[–()&]',\" \").str.replace('&gt;', ' ').str.replace(r\"\\s\\s\\s?\", ' ')\n",
        "onoma_a_tweets_df['clean_text'] = onoma_a_tweets_df['clean_text'].str.replace(r\"\\w*…\", \"\")"
      ],
      "metadata": {
        "id": "-RghdC_u39BQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Αν θέλετε μπορείτε να πετάξετε και τα RTs, τα hashtags και τα @names για να έχετε μόνο το κείμενο"
      ],
      "metadata": {
        "id": "O-ruleZ75NWM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Aφαίρεση των #hashtags, των @names και των RT\n",
        "onoma_a_tweets_df['clean_text'] = onoma_a_tweets_df['clean_text'].str.replace(r'RT\\s', '').str.replace(r'@[\\w\\_]*\\s', '').str.replace(r\"#[\\w\\W\\d]*\",\"\")#.str.replace(r'http[s\\s/\\\\.]*', '')"
      ],
      "metadata": {
        "id": "tYKmF6n65Gi0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ελέγξτε πώς πήγε το καθάρισμα συγκρίνοντας το full_text με το clean_text"
      ],
      "metadata": {
        "id": "wqWgr0T-5nDI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check cleaning results\n",
        "onoma_a_tweets_df.loc[15:20][['full_text', 'clean_text']] # αλλάζοντας τα νούμερα στο loc, επισκοπω διαφορετικά rows "
      ],
      "metadata": {
        "id": "6n0BCary5wFR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Μετατροπή του κειμένου σε lowercase\n",
        "onoma_a_tweets_df['clean_text'] = onoma_a_tweets_df['clean_text'].str.lower()\n",
        "\n",
        "# View dataframe\n",
        "onoma_a_tweets_df.head(1)"
      ],
      "metadata": {
        "id": "Hw4SM4Le6O9t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Μετρήστε τις λέξεις του κάθε tweet (του κάθε row)"
      ],
      "metadata": {
        "id": "s3MoS-3d7JYX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "onoma_a_tweets_df['clean_text'].str.split().str.len() "
      ],
      "metadata": {
        "id": "bLtHhPSf8Jcy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Προσθέστε στο τέλος του προηγούμενου κώδικα ό,τι χρειάζεται για να δείτε το μ.ο. των λέξεων στα tweets"
      ],
      "metadata": {
        "id": "ARBbqUrD8nqt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "5egZ_2XR88xl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Μπορείτε να σκεφτείτε άλλα ερωτήματα και να πάρετε τις απαντήσεις;"
      ],
      "metadata": {
        "id": "RCwKjW4j9HrX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####**Δεύτερο dataset** (δώστε το όνομα του δικού σας δεύτερου dataset)"
      ],
      "metadata": {
        "id": "5CnAw2QC-gKU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Επαναλάβετε τα παραπάνω για το δεύτερο dataset των tweets"
      ],
      "metadata": {
        "id": "1R68zLAL-mh_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Wordclouds**"
      ],
      "metadata": {
        "id": "0tdxEdtM9041"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####**Εισαγωγή βιβλιοθηκών**"
      ],
      "metadata": {
        "id": "QBgzpOCp-4-B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from wordcloud import WordCloud, STOPWORDS"
      ],
      "metadata": {
        "id": "PqrIZReM95MI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####**Πρώτο dataset** (δώστε το όνομα του δικού σας πρώτου dataset)"
      ],
      "metadata": {
        "id": "82nsGKC__wyu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Δημιουργία ενός text που θα περιέχει τα κείμενα από όλα τα tweets του dataset (δεν έχει νόημα να κάνουμε wordcloud από ένα - ένα τα tweets. Θέλουμε να δούμε τι γίνεται σε μεγάλα κείμενα π.χ. σε ολόκληρα βιβλία, σε πολιτικούς λόγους, σε μεγάλα σύνολα δημοσιευμάτων κλπ., άρα θέλουμε να δούμε τι γίνεται στο λόγο που χρησιμοποιεί ένας twitter user σε όλα τα tweets του που διαθέτουμε)"
      ],
      "metadata": {
        "id": "F1f5eupC_Wh6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Concatenate tweets' texts\n",
        "text_a = onoma_a_tweets_df['clean_text'].str.cat(sep = ' ')#.replace(\"amp\", ' ')\n",
        "# View text\n",
        "text_a"
      ],
      "metadata": {
        "id": "MX_r4XIv_UIx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Σύντομη επανάληψη**\n",
        "\n",
        "Θέλουμε να φτιάξουμε ένα συννεφόλεξο, δηλαδή ένα γραφικό στο οποίο οι λέξεις που περιέχονται σε ένα κείμενο εμφανίζονται με διαφορετικό μέγεθος γραμμάτων ανάλογα με τη συχνότητα εμφάνισής τους.\n",
        "\n",
        "Οι συχνότερες όμως λέξεις σε ένα κείμενο είναι τα άρθρα, οι σύνδεσμοι κλπ. Για να μην εμφανίζονται αυτές οι λέξεις, χρησιμοποιούμε ένα φίλτρο για να μην τις μετράει το wordcloud. Αυτό το φίλτρο στην ουσία είναι ένα λεξικό με ανεπιθύμητες λέξεις που ονομάζεται STOPWORDS.\n",
        "\n",
        "Όπως θα θυμάστε από το μάθημα, τα STOPWORDS που περιέχει το WordCloud είναι στα αγγλικά, άρα δεν μας είναι χρήσιμο σε ελληνικά κείμενα. Γι' αυτό χρησιμοποιούμε τα ελληνικά stopwords που έχει η spacy."
      ],
      "metadata": {
        "id": "1ltsEcjEA759"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**WordCloud**"
      ],
      "metadata": {
        "id": "5zFl39o4EcqP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import spacy\n",
        "import spacy\n",
        "# Load small version of spacy's dictionary that contains greek words used in news\n",
        "nlp = spacy.load('el_core_news_sm')"
      ],
      "metadata": {
        "id": "HfcquHLvEhgY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wordcloud = WordCloud(\n",
        "    stopwords = nlp.Defaults.stop_words, # stopwords from 'el_core_news_sm' dictionary\n",
        "    width = 2000,\n",
        "    height = 1000,\n",
        "    background_color = 'black'\n",
        "    ).generate(text_a) # εδώ δηλώνουμε από ποιο κείμενο θα φτιάξει το wordcloud\n",
        "fig = plt.figure(\n",
        "    figsize = (40, 30),\n",
        "    facecolor = 'k',\n",
        "    edgecolor = 'k')\n",
        "plt.imshow(wordcloud, interpolation = 'bilinear')\n",
        "plt.axis('off')\n",
        "plt.tight_layout(pad=0)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "0bpm4mqEFPNr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Όπως βλέπουμε, ίδιες λέξεις που βρίσκονται σε διαφορετικές πτώσεις/αριθμούς/χρόνους/πρόσωπα, εμφανίζονται σαν διαφορετικές λέξεις. Για να λύσουμε αυτό το πρόβλημα, χρησιμοποιούμε τo lemmatization της spacy (που έχουμε φορτώσει σαν nlp)..."
      ],
      "metadata": {
        "id": "xxsbznhpGiQy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "doc_a = nlp(text_a) # περνάμε το text από την nlp\n",
        "lemma_text_a = ' '.join(token.lemma_ for token in doc_a) # εφαρμόζουμε lemmatization σε κάθε λέξη"
      ],
      "metadata": {
        "id": "ElPXE9pTJl29"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "...και ξαναφτιάχνουμε το wordcloud"
      ],
      "metadata": {
        "id": "j7VgeN3wKh-v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "wordcloud = WordCloud(\n",
        "    stopwords = nlp.Defaults.stop_words, \n",
        "    width = 2000,\n",
        "    height = 1000,\n",
        "    background_color = 'black'\n",
        "    ).generate(lemma_text_a) # βάζουμε το lemmatized text\n",
        "fig = plt.figure(\n",
        "    figsize = (40, 30),\n",
        "    facecolor = 'k',\n",
        "    edgecolor = 'k')\n",
        "plt.imshow(wordcloud, interpolation = 'bilinear')\n",
        "plt.axis('off')\n",
        "plt.tight_layout(pad=0)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Qe1CkMUaK1Tr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####**Δεύτερο dataset** (δώστε το όνομα του δικού σας δεύτερου dataset)"
      ],
      "metadata": {
        "id": "95divw5RLNSO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Επαναλάβετε τα παραπάνω για το δεύτερο dataset των tweets"
      ],
      "metadata": {
        "id": "tj7tlgW4LNSP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "G5zV71i3MzNP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "H-tvo0ggMzIv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Challenge επανάληψης:**\n",
        "\n",
        "Μπορείτε να συνενώσετε τα δύο dataframes (merge) ώστε να πάρετε ωραία συγκριτικά γραφήματα για τα στατιστικά τους στοιχεία;"
      ],
      "metadata": {
        "id": "S14ZBb1yMS9d"
      }
    }
  ]
}